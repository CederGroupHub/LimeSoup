From cou.: 0 Journal
From Soup: 0 Mol. BioSyst.
 ###### 
From cou.: 1 Here we present a novel statistical methodology that allows us to analyze gene expression data that have been collected from a number of different cases or conditions in a unified framework. Using a Bayesian nonparametric framework we develop a hierarchical model wherein genes can maintain a shared set of interactions between different cases, whilst also exhibiting behaviour that is unique to specific cases, sets of conditions, or groups of data points. By doing so we are able to not only combine data from different cases but also to discern the unique regulatory interactions that differentiate the cases. We apply our method to clinical data collected from patients suffering from sporadic Inclusion Body Myositis (sIBM), as well as control samples, and demonstrate the ability of our method to infer regulatory interactions that are unique to the disease cases of interest. The method thus balances the statistical need to include as many patients and controls as possible, and the clinical need to maintain potentially cryptic differences among patients and between patients and controls at the regulatory level.
From Soup: 1 Here we present a novel statistical methodology that allows us to analyze gene expression data that have been collected from a number of different cases or conditions in a unified framework. Using a Bayesian nonparametric framework we develop a hierarchical model wherein genes can maintain a shared set of interactions between different cases, whilst also exhibiting behaviour that is unique to specific cases, sets of conditions, or groups of data points. By doing so we are able to not only combine data from different cases but also to discern the unique regulatory interactions that differentiate the cases. We apply our method to clinical data collected from patients suffering from sporadic Inclusion Body Myositis (sIBM), as well as control samples, and demonstrate the ability of our method to infer regulatory interactions that are unique to the disease cases of interest. The method thus balances the statistical need to include as many patients and controls as possible, and the clinical need to maintain potentially cryptic differences among patients and between patients and controls at the regulatory level.
 ###### 
From cou.: 2 Sporadic Inclusion Body Myositis (sIBM) is a disease that causes inflammation and progressive weakening and wasting of the muscles, and the mechanisms by which it acts are not currently fully understood.1,2 Here we develop and apply a method to medical data from a study of sIBM patients, controls, and disease controls that allows us to identify the differences in the regulatory network structure that are specific to individuals with the disease.
From Soup: 2 Sporadic Inclusion Body Myositis (sIBM) is a disease that causes inflammation and progressive weakening and wasting of the muscles, and the mechanisms by which it acts are not currently fully understood. 1,2 Here we develop and apply a method to medical data from a study of sIBM patients, controls, and disease controls that allows us to identify the differences in the regulatory network structure that are specific to individuals with the disease.
 ###### 
From cou.: 3 When analysing gene expression data sets, a frequently made assumption is that the regulatory interactions influencing the expression of the genes remain identical across all of the observed data points. Of course in reality regulatory interactions between genes are not simple direct processes, but require a number of intermediate steps that may themselves be governed by further unobserved processes. For example, on the scale of a single pair of genes, it may be the case that a protein product must be phosphorylated before it can bind to a transcription factor binding site to promote (or inhibit) transcription, and this phosphorylation may be controlled by a signalling pathway whose behaviour cannot be observed fully using mRNA level expression studies. Other such processes might include transport of proteins into the nucleus, formation of complexes or further post-translational modifications. As a result the regulatory interactions in effect at any given time may vary due to environmental conditions such as external stresses; or simply as part of cellular processes such as the cell cycle; or on a smaller localised scale, due to the behaviour of metabolic processes or signalling pathways.
From Soup: 3 When analysing gene expression data sets, a frequently made assumption is that the regulatory interactions influencing the expression of the genes remain identical across all of the observed data points. Of course in reality regulatory interactions between genes are not simple direct processes, but require a number of intermediate steps that may themselves be governed by further unobserved processes. For example, on the scale of a single pair of genes, it may be the case that a protein product must be phosphorylated before it can bind to a transcription factor binding site to promote (or inhibit) transcription, and this phosphorylation may be controlled by a signalling pathway whose behaviour cannot be observed fully using mRNA level expression studies. Other such processes might include transport of proteins into the nucleus , formation of complexes or further post-translational modifications. As a result the regulatory interactions in effect at any given time may vary due to environmental conditions such as external stresses; or simply as part of cellular processes such as the cell cycle; or on a smaller localised scale, due to the behaviour of metabolic processes or signalling pathways.
 ###### 
From cou.: 4 Previously this problem has been addressed in the context of gene expression time series modelling; for example in the work of Lèbre et al.3 time series were divided into a number of distinct segments; and the work of Grzegorczyk et al.4 allocated indicator variables determining the network structure to observations; Thorne and Stumpf5 took a Bayesian nonparametric approach in order to infer temporally varying networks. It can be seen from the results presented in these papers that it is crucial to allow for variation in the network structure explicitly and from the outset in any statistical analysis; failing to do so assumes an incorrect model and will inevitably bias the results, since the assumption of a static set of interactions is not biologically realistic. Given suitable tools, however, it is possible to infer when and where changes to the network structure take place and include such phenomena into the model, not only enhancing the accuracy of the inferred network structure but also potentially imparting novel biological insights.
From Soup: 4 Previously this problem has been addressed in the context of gene expression time series modelling; for example in the work of Lèbre et al. 3 time series were divided into a number of distinct segments; and the work of Grzegorczyk et al. 4 allocated indicator variables determining the network structure to observations; Thorne and Stumpf 5 took a Bayesian nonparametric approach in order to infer temporally varying networks. It can be seen from the results presented in these papers that it is crucial to allow for variation in the network structure explicitly and from the outset in any statistical analysis; failing to do so assumes an incorrect model and will inevitably bias the results, since the assumption of a static set of interactions is not biologically realistic. Given suitable tools, however, it is possible to infer when and where changes to the network structure take place and include such phenomena into the model, not only enhancing the accuracy of the inferred network structure but also potentially imparting novel biological insights.
 ###### 
From cou.: 5 Here we aim to address a different aspect of this problem and consider the situation in which we may be presented with multiple sets of gene expression data that are not part of a time series but that have been observed under different conditions. Thus we have prior knowledge that some aspects of the regulatory network structure will most likely vary between the samples. A naive approach would be to simply attempt to infer regulatory network structures for each data set independently. However, this risks the loss of statistical power and, furthermore, it is not realistic to expect the entire regulatory network structure to change between conditions: for some genes the interactions ought to be the same across all of the data sets, and by attempting to infer these independently we are effectively throwing away valuable information.
From Soup: 5 Here we aim to address a different aspect of this problem and consider the situation in which we may be presented with multiple sets of gene expression data that are not part of a time series but that have been observed under different conditions. Thus we have prior knowledge that some aspects of the regulatory network structure will most likely vary between the samples. A naive approach would be to simply attempt to infer regulatory network structures for each data set independently. However, this risks the loss of statistical power and, furthermore, it is not realistic to expect the entire regulatory network structure to change between conditions: for some genes the interactions ought to be the same across all of the data sets, and by attempting to infer these independently we are effectively throwing away valuable information.
 ###### 
From cou.: 6 To counter this problem we propose a methodology that applies a hierarchical model of the regulatory interactions of genes that allows the distribution of observed interactions to vary between conditions, but also allows interactions to be shared across multiple data sets. The approach is similar to that of Penfold et al.,6 but instead of using a Bayesian nonparametric model of the regulatory network and a traditional Bayesian model of the hierarchical structures, we apply a hierarchical Bayesian nonparametric model. This idea has also been explored previously in Chiquet et al.7 in a frequentist framework, but taking a Bayesian nonparametric approach has a number of advantages. Bayesian nonparametrics allows us to derive models where the number of parameters in the model can vary in order to describe the observed data at an appropriate level of detail. Thus as the data become more complex the model can adapt to describe this complexity without further user intervention; the approach is therefore generally valid over a larger range of possible observations than a traditional Bayesian model. One application of Bayesian nonparametrics that has seen significant attention in recent years is the use of Bayesian nonparametric mixture models, where the number of mixture components is allowed to vary as necessary to describe the observed data. Here we have applied a hierarchical form of such a model, so that the number of observed network structures can vary to describe the data, whilst maintaining a hierarchical structure that encodes our a priori knowledge of the differing conditions between the data sets. Thus regulatory networks can be inferred that take different structures between data points, whilst potentially sharing network structures between conditions, with the variation in the network structure adapting as necessary to explain the observed data. This approach forms an ideal framework for systems medicine applications, where the rational generation of functional hypotheses related to disease aetiology is increasingly called for.
From Soup: 6 To counter this problem we propose a methodology that applies a hierarchical model of the regulatory interactions of genes that allows the distribution of observed interactions to vary between conditions, but also allows interactions to be shared across multiple data sets. The approach is similar to that of Penfold et al. , 6 but instead of using a Bayesian nonparametric model of the regulatory network and a traditional Bayesian model of the hierarchical structures, we apply a hierarchical Bayesian nonparametric model. This idea has also been explored previously in Chiquet et al. 7 in a frequentist framework, but taking a Bayesian nonparametric approach has a number of advantages. Bayesian nonparametrics allows us to derive models where the number of parameters in the model can vary in order to describe the observed data at an appropriate level of detail. Thus as the data become more complex the model can adapt to describe this complexity without further user intervention; the approach is therefore generally valid over a larger range of possible observations than a traditional Bayesian model. One application of Bayesian nonparametrics that has seen significant attention in recent years is the use of Bayesian nonparametric mixture models, where the number of mixture components is allowed to vary as necessary to describe the observed data. Here we have applied a hierarchical form of such a model, so that the number of observed network structures can vary to describe the data, whilst maintaining a hierarchical structure that encodes our a priori knowledge of the differing conditions between the data sets. Thus regulatory networks can be inferred that take different structures between data points, whilst potentially sharing network structures between conditions, with the variation in the network structure adapting as necessary to explain the observed data. This approach forms an ideal framework for systems medicine applications, where the rational generation of functional hypotheses related to disease aetiology is increasingly called for.
 ###### 
From cou.: 7 Graphical models have been used extensively in the modelling of regulatory networks in Systems Biology,8–10 and here we present a method of Graphical Gaussian Model (GGM) inference based on a novel combination of existing methods, that can easily be incorporated in our Bayesian nonparametric framework. This provides us with a computationally efficient and robust method to infer regulatory networks for large numbers of genes.
From Soup: 7 Graphical models have been used extensively in the modelling of regulatory networks in Systems Biology, 8–10 and here we present a method of Graphical Gaussian Model (GGM) inference based on a novel combination of existing methods, that can easily be incorporated in our Bayesian nonparametric framework. This provides us with a computationally efficient and robust method to infer regulatory networks for large numbers of genes.
 ###### 
From cou.: 8 We model the expression levels of a set of genes as a Gaussian Graphical Model (GGM),11 whereby considering the expression levels as random variables, we use an undirected graph to represent the relationships between these variables. Edges between nodes of the graph are absent only if the two variables are conditionally independent of one another given the observations of the remaining variables.
From Soup: 8 We model the expression levels of a set of genes as a Gaussian Graphical Model (GGM), 11 whereby considering the expression levels as random variables, we use an undirected graph to represent the relationships between these variables. Edges between nodes of the graph are absent only if the two variables are conditionally independent of one another given the observations of the remaining variables.
 ###### 
From cou.: 9 Considering a set of genes X1,…,Xp, the GGM assumes a multivariate normal distribution for the Xi, so that
From Soup: 9 Considering a set of genes X 1 ,…, X p , the GGM assumes a multivariate normal distribution for the X i , so that
 ###### 
From cou.: 10 matrix
From Soup: 10 matrix
 ###### 
From cou.: 11 Σ
From Soup: 11 Σ
 ###### 
From cou.: 12 X
From Soup: 12 X
 ###### 
From cou.: 13 i
From Soup: 13 i
 ###### 
From cou.: 14 X
From Soup: 14 X
 ###### 
From cou.: 15 j
From Soup: 15 j
 ###### 
From cou.: 16 Z
From Soup: 16 Z
 ###### 
From cou.: 17 X
From Soup: 17 X
 ###### 
From cou.: 18 k
From Soup: 18 k ≠ i , j
 ###### 
From cou.: 19 i
From Soup: 19 X
 ###### 
From cou.: 20 j
From Soup: 20 Z
 ###### 
From cou.: 21 X
From Soup: 21 R
 ###### 
From cou.: 22 Z
From Soup: 22 XZ
 ###### 
From cou.: 23 R
From Soup: 23 i
 ###### 
From cou.: 24 XZ
From Soup: 24 j
 ###### 
From cou.: 25 i
From Soup: 25 ρ
 ###### 
From cou.: 26 j
From Soup: 26 ijZ
 ###### 
From cou.: 27 ρ
From Soup: 27 Σ
 ###### 
From cou.: 28 ijZ
From Soup: 28 Σ
 ###### 
From cou.: 29 Σ
From Soup: 29 −1
 ###### 
From cou.: 30 Σ
From Soup: 30 p
 ###### 
From cou.: 31 −1
From Soup: 31 n
 ###### 
From cou.: 32 p
From Soup: 32 matrix
 ###### 
From cou.: 33 n
From Soup: 33 Σ
 ###### 
From cou.: 34 matrix
From Soup: 34 −1
 ###### 
From cou.: 35 Σ
From Soup: 35 Σ
 ###### 
From cou.: 36 −1
From Soup: 36 Fortunately, we can still estimate the partial correlations between variables using regularised regression techniques. By defining a regression model for each of the p variables X 1 ,…, X p as
 ###### 
From cou.: 37 Σ
From Soup: 37 ε
 ###### 
From cou.: 38 Fortunately, we can still estimate the partial correlations between variables using regularised regression techniques. By defining a regression model for each of the p variables X1,…,Xp as
From Soup: 38 σ
 ###### 
From cou.: 39 ε
From Soup: 39 2
 ###### 
From cou.: 40 σ
From Soup: 40 et al.
 ###### 
From cou.: 41 2
From Soup: 41 12
 ###### 
From cou.: 42 et al.
From Soup: 42 υ
 ###### 
From cou.: 43 12
From Soup: 43 i
 ###### 
From cou.: 44 υ
From Soup: 44 j
 ###### 
From cou.: 45 i
From Soup: 45 et al.
 ###### 
From cou.: 46 j
From Soup: 46 12
 ###### 
From cou.: 47 et al.
From Soup: 47 13
 ###### 
From cou.: 48 12
From Soup: 48 13,14
 ###### 
From cou.: 49 13
From Soup: 49 Like Caron and Doucet 13 we proceed by placing a mixture of Gaussian distributions as the prior on the regression coefficients υ j . Omitting the variable specific indices υ i for clarity,
 ###### 
From cou.: 50 13,14
From Soup: 50 υ
 ###### 
From cou.: 51 Like Caron and Doucet13 we proceed by placing a mixture of Gaussian distributions as the prior on the regression coefficients υj. Omitting the variable specific indices υi for clarity,
From Soup: 51 j
 ###### 
From cou.: 52 υ
From Soup: 52 p
 ###### 
From cou.: 53 j
From Soup: 53 ζ
 ###### 
From cou.: 54 p
From Soup: 54 j
 ###### 
From cou.: 55 ζ
From Soup: 55 ζ
 ###### 
From cou.: 56 j
From Soup: 56 j
 ###### 
From cou.: 57 ζ
From Soup: 57 13
 ###### 
From cou.: 58 j
From Soup: 58 p
 ###### 
From cou.: 59 13
From Soup: 59 ζ
 ###### 
From cou.: 60 p
From Soup: 60 j
 ###### 
From cou.: 61 ζ
From Soup: 61 ω
 ###### 
From cou.: 62 j
From Soup: 62 κ
 ###### 
From cou.: 63 ω
From Soup: 63 υ
 ###### 
From cou.: 64 κ
From Soup: 64 j
 ###### 
From cou.: 65 υ
From Soup: 65 13
 ###### 
From cou.: 66 j
From Soup: 66 Given values of the regression coefficients υ i j for each variable i we can estimate the partial correlations 12 as
 ###### 
From cou.: 67 13
From Soup: 67 For some probability measure, H , and concentration parameter, α , the corresponding Dirichlet process, denoted by DP( α , H ), defines a distribution over probability distributions, so that if G ∼ DP( α , H ) then G is itself a probability measure. The fundamental property of a Dirichlet process, introduced in the seminal work of Ferguson, 15 is that for any partition of the measurable space on which H is defined, the vector ( G ( S 1 ),…, G ( S n )) is distributed as a Dirichlet distribution, Dir( αH ( S 1 ),…, αH ( S n )). There are a number of different constructions of the Dirichlet process, which we will not cover here, but which are described in more detail in e.g. Teh et al . 16 Instead we focus on the Chinese Restaurant Process (CRP) that has a natural interpretation that lends itself well to the Hierarchical Dirichlet process extension described below.
 ###### 
From cou.: 68 Given values of the regression coefficients υij for each variable i we can estimate the partial correlations12 as
From Soup: 68 The Chinese Restaurant Process analogy describes (marginalised) draws from some G ∼ DP( α , H ) as customers at a restaurant. The first customer is served a dish ψ 1 ∼ H and seated at the first table. Subsequent customers are seated at one of the K existing tables in the restaurant with probability proportional to the number of customers already seated at each table; or at a new table with probability proportional to α . At each table a single dish is served, corresponding to the value of the observations. This is illustrated in Fig. 1 . When a new table is chosen a dish is sampled at random from H . For observations θ i from G , denoting the counts of customers at each table t as m t , the CRP can be formally defined as
 ###### 
From cou.: 69 For some probability measure, H, and concentration parameter, α, the corresponding Dirichlet process, denoted by DP(α,H), defines a distribution over probability distributions, so that if G ∼ DP(α,H) then G is itself a probability measure. The fundamental property of a Dirichlet process, introduced in the seminal work of Ferguson,15 is that for any partition of the measurable space on which H is defined, the vector (G(S1),…,G(Sn)) is distributed as a Dirichlet distribution, Dir(αH(S1),…,αH(Sn)). There are a number of different constructions of the Dirichlet process, which we will not cover here, but which are described in more detail in e.g. Teh et al.16 Instead we focus on the Chinese Restaurant Process (CRP) that has a natural interpretation that lends itself well to the Hierarchical Dirichlet process extension described below.
From Soup: 69 indicator
 ###### 
From cou.: 70 The Chinese Restaurant Process analogy describes (marginalised) draws from some G ∼ DP(α,H) as customers at a restaurant. The first customer is served a dish ψ1 ∼ H and seated at the first table. Subsequent customers are seated at one of the K existing tables in the restaurant with probability proportional to the number of customers already seated at each table; or at a new table with probability proportional to α. At each table a single dish is served, corresponding to the value of the observations. This is illustrated in Fig. 1. When a new table is chosen a dish is sampled at random from H. For observations θi from G, denoting the counts of customers at each table t as mt, the CRP can be formally defined as
From Soup: 70 z
 ###### 
From cou.: 71 indicator
From Soup: 71 l
 ###### 
From cou.: 72 z
From Soup: 72 F
 ###### 
From cou.: 73 l
From Soup: 73 x
 ###### 
From cou.: 74 F
From Soup: 74 l
 ###### 
From cou.: 75 x
From Soup: 75 X
 ###### 
From cou.: 76 l
From Soup: 76 l
 ###### 
From cou.: 77 X
From Soup: 77 F
 ###### 
From cou.: 78 l
From Soup: 78 ψ
 ###### 
From cou.: 79 F
From Soup: 79 z l
 ###### 
From cou.: 80 ψ
From Soup: 80 The Hierarchical Dirichlet process is a natural extension of the Dirichlet process whereby the base measure of a set of Dirichlet process distributed G s is itself Dirichlet process distributed, here denoted G 0 . Thus G 0 ∼ DP( γ , H ) and G s ∼ DP( α , G 0 ), and samples from each group s are drawn from G s . In the CRP analogy for the HDP, termed the Chinese Restaurant Franchise (CRF) and illustrated in Fig. 2 , each group corresponds to a restaurant, and customers from each group are assigned to the corresponding restaurant. Customers again sit at occupied tables with probability proportional to the number of customers at the table, or choose a new table with probability proportional to α . However, when a customer chooses a new table, dishes are drawn from a franchise wide menu with probability proportional to the number of tables having that dish across all of the restaurants in the franchise, or a new dish drawn from H with probability proportional to γ . Thus multiple tables within a restaurant may serve the same dish, and dishes are shared across all of the restaurants. Constructing a Hierarchical Dirichlet process mixture model, where observations x sl from group s are drawn from some emission distribution F with parameters θ sl , we derive a model as illustrated in Fig. 3 .
 ###### 
From cou.: 81 z
From Soup: 81 In the context we consider here, groups are cases within a gene expression study over several different conditions. The emission distribution is considered to be a regression model where each gene i is allowed to have a set of parameters ν i , ζ i that can vary between observations, represented by the assignment of an indicator variable z sl to each observation, indexing the parameters (or in the CRF analogy, dish) generating the observation. In the CRF analogy, dishes can be shared across multiple restaurants, and the same is true here of the regulatory interactions of a gene across conditions. In practice this means that it is possible for the interactions of a gene to exhibit a wide variety of behaviours, if necessary to explain the data; they may vary between observations within a single condition, vary across conditions, or remain the same over multiple conditions.
 ###### 
From cou.: 82 l
From Soup: 82 Since we can consider each gene independently, inferring an indicator sequence z i sl and set of regression coefficients for gene i , we will omit the gene specific indices in the description below for clarity. To draw posterior samples from the Hierarchical Dirichlet process we employ the direct assignment scheme described in Teh et al. , 16 where an indicator variable is used to define the assignment of global mixture components to each observation rather than directly keeping track of the table assignments within the CRF scheme. Only the indicator variables z sl , counts m sk of customers at tables in restaurant s serving dish k , and the vector of global mixing proportions β are sampled, whilst the counts n − sl sk of customers in restaurant s eating dish k , excluding customer l of restaurant s , can be derived from z . The Gibbs sampling scheme is then with ψ k = ( ν k , ζ k ), x − sl being x excluding observation l in group s , f being the likelihood function, and new values of ψ being sampled from the prior. Then for m , where s ( a , b ) denotes the Stirling number of the first kind, and finally This is then combined with the MCMC sampler for the regression parameters υ and ζ described in Caron and Doucet. 13 For each ψ k based on the data points X k i , Y k i = X k j ≠ i , across all of the cases having indicator value k , we sample, where , Z = diag(1/ ζ 2 ), , and with being the modified Bessel function of the second kind, and indices k of the υ , ζ are omitted for clarity.
 ###### 
From cou.: 83 The Hierarchical Dirichlet process is a natural extension of the Dirichlet process whereby the base measure of a set of Dirichlet process distributed Gs is itself Dirichlet process distributed, here denoted G0. Thus G0 ∼ DP(γ,H) and Gs ∼ DP(α,G0), and samples from each group s are drawn from Gs. In the CRP analogy for the HDP, termed the Chinese Restaurant Franchise (CRF) and illustrated in Fig. 2, each group corresponds to a restaurant, and customers from each group are assigned to the corresponding restaurant. Customers again sit at occupied tables with probability proportional to the number of customers at the table, or choose a new table with probability proportional to α. However, when a customer chooses a new table, dishes are drawn from a franchise wide menu with probability proportional to the number of tables having that dish across all of the restaurants in the franchise, or a new dish drawn from H with probability proportional to γ. Thus multiple tables within a restaurant may serve the same dish, and dishes are shared across all of the restaurants. Constructing a Hierarchical Dirichlet process mixture model, where observations xsl from group s are drawn from some emission distribution F with parameters θsl, we derive a model as illustrated in Fig. 3.
From Soup: 83 We extracted RNA from frozen muscle biopsies of patients affected by clinically and pathologically confirmed sporadic inclusion body myositis (sIBM; n = 6) and polymyositis ( n = 3), and used pathologically normal muscle biopsies as controls ( n = 4). Such small numbers are typical for many diseases, and statistical methods that do not crudely divide such data further are required in order to derive better insights from such data.
 ###### 
From cou.: 84 In the context we consider here, groups are cases within a gene expression study over several different conditions. The emission distribution is considered to be a regression model where each gene i is allowed to have a set of parameters νi, ζi that can vary between observations, represented by the assignment of an indicator variable zsl to each observation, indexing the parameters (or in the CRF analogy, dish) generating the observation. In the CRF analogy, dishes can be shared across multiple restaurants, and the same is true here of the regulatory interactions of a gene across conditions. In practice this means that it is possible for the interactions of a gene to exhibit a wide variety of behaviours, if necessary to explain the data; they may vary between observations within a single condition, vary across conditions, or remain the same over multiple conditions.
From Soup: 84 RNA quality control was performed with RNA 6000 NanoChips on the Agilent 2100 Bioanalyzer (Agilent, Palo Alto, USA). Biotin -labelled target were prepared using 250 ng of total RNA and cDNA was synthesized using the GeneChip® WT (Whole Transcript) Sense Target Labelling and Control Reagents kit as described by the manufacturer (Affymetrix). The sense cDNA was then fragmented and biotin -labelled with TdT (terminal deoxynucleotidyl transferase) using the GeneChip® WT Terminal labelling kit (Affymetrix, Santa Clara, USA). 5 micrograms of biotinylated target were used for hybridization, which was incubated with the GeneChip® Human Exon 1.0 ST array (Affymetrix) at 45 °C for 16–20 hours. Following hybridization, the GeneChip® Hybridization, Wash and Stain kit, and the GeneChip® Fluidics Station 450 (Affymetrix) were used to remove non-specifically bound material and for detection of specifically bound target. The arrays were scanned using the GeneChip® Scanner 3000 7G (Affymetrix) and raw data was extracted from the scanned images and analyzed with the Affymetrix Power Tools software package (Affymetrix). Preliminary analyses revealed that one of the sIBM data points and one of the control data points were abnormal, these were removed from the study giving 5 data points for sIBM, and 3 each for control and polymyositis.
 ###### 
From cou.: 85 Since we can consider each gene independently, inferring an indicator sequence zisl and set of regression coefficients for gene i, we will omit the gene specific indices in the description below for clarity. To draw posterior samples from the Hierarchical Dirichlet process we employ the direct assignment scheme described in Teh et al.,16 where an indicator variable is used to define the assignment of global mixture components to each observation rather than directly keeping track of the table assignments within the CRF scheme. Only the indicator variables zsl, counts msk of customers at tables in restaurant s serving dish k, and the vector of global mixing proportions β are sampled, whilst the counts n−slsk of customers in restaurant s eating dish k, excluding customer l of restaurant s, can be derived from z. The Gibbs sampling scheme is thenwith ψk = (νk,ζk), x−sl being x excluding observation l in group s, f being the likelihood function, and new values of ψ being sampled from the prior. Then for m,where s(a,b) denotes the Stirling number of the first kind, and finallyThis is then combined with the MCMC sampler for the regression parameters υ and ζ described in Caron and Doucet.13 For each ψk based on the data points Xki, Yki = Xkj≠i, across all of the cases having indicator value k, we sample,where , Z = diag(1/ζ2), , andwith being the modified Bessel function of the second kind, and indices k of the υ, ζ are omitted for clarity.
From Soup: 85 Expression data were obtained and processed from the Affymetrix CEL files using the R packages oligo 17 and limma. 18 We applied an RMA (Robust Multi-array Average 19 ) transformation to the intensity data. This normalization step includes median polish (to summarize data across probe replicates) and a quantile normalization across arrays (to make the arrays comparable).
 ###### 
From cou.: 86 We extracted RNA from frozen muscle biopsies of patients affected by clinically and pathologically confirmed sporadic inclusion body myositis (sIBM; n = 6) and polymyositis (n = 3), and used pathologically normal muscle biopsies as controls (n = 4). Such small numbers are typical for many diseases, and statistical methods that do not crudely divide such data further are required in order to derive better insights from such data.
From Soup: 86 The methods described above were implemented using the R statistical environment. When running the method on the experimental data presented in this paper run times were around 20 hours when running inferences in parallel using a 12 core server.
 ###### 
From cou.: 87 RNA quality control was performed with RNA 6000 NanoChips on the Agilent 2100 Bioanalyzer (Agilent, Palo Alto, USA). Biotin-labelled target were prepared using 250 ng of total RNA and cDNA was synthesized using the GeneChip® WT (Whole Transcript) Sense Target Labelling and Control Reagents kit as described by the manufacturer (Affymetrix). The sense cDNA was then fragmented and biotin-labelled with TdT (terminal deoxynucleotidyl transferase) using the GeneChip® WT Terminal labelling kit (Affymetrix, Santa Clara, USA). 5 micrograms of biotinylated target were used for hybridization, which was incubated with the GeneChip® Human Exon 1.0 ST array (Affymetrix) at 45 °C for 16–20 hours. Following hybridization, the GeneChip® Hybridization, Wash and Stain kit, and the GeneChip® Fluidics Station 450 (Affymetrix) were used to remove non-specifically bound material and for detection of specifically bound target. The arrays were scanned using the GeneChip® Scanner 3000 7G (Affymetrix) and raw data was extracted from the scanned images and analyzed with the Affymetrix Power Tools software package (Affymetrix). Preliminary analyses revealed that one of the sIBM data points and one of the control data points were abnormal, these were removed from the study giving 5 data points for sIBM, and 3 each for control and polymyositis.
From Soup: 87 The accuracy of our methodology was first evaluated by generating synthetic data for 10 genes with a known underlying network structure, that varies over 30 data points. Some genes were assigned interactions that remained constant across all of the data points, whereas others were involved in interactions that were specific to certain groups of data points. We ran our method over 5000 Gibbs sampler iterations, collecting 500 samples after 4500 burn-in iterations, to infer the interactions of each gene and estimate how they varied.
 ###### 
From cou.: 88 Expression data were obtained and processed from the Affymetrix CEL files using the R packages oligo17 and limma.18 We applied an RMA (Robust Multi-array Average19) transformation to the intensity data. This normalization step includes median polish (to summarize data across probe replicates) and a quantile normalization across arrays (to make the arrays comparable).
From Soup: 88 The output of the method is plotted in Fig. 4 , with genes whose interactions did not change between data points (6 out of 10, all of which were correctly identified by our method) omitted for clarity. Our results show that the method correctly identifies the genes whose interactions vary in specific sets of data points, and whilst the identification of the nature of the variations between data points is not perfect, we use a realistically small number of samples, so that perfect accuracy is not to be expected. It is also worth noting that whilst we infer some superfluous clusters in Fig. 4(a, c, d) , these are almost entirely unique to the relevant groups of data points and do not incorrectly span multiple interaction sets. For example in Fig. 4(d) , whilst data points 1–20 should share one set of interactions, two are incorrectly inferred, but these are correctly inferred to be unique to data points 1–20, and do not appear for data points 21–30.
 ###### 
From cou.: 89 The methods described above were implemented using the R statistical environment. When running the method on the experimental data presented in this paper run times were around 20 hours when running inferences in parallel using a 12 core server.
From Soup: 89 We then applied our method to the sIBM data set described above, again running 5000 iterations of our Gibbs sampler with 4500 iterations of burn-in before collecting 500 samples. To render the analysis tractable we selected a subset of probes from the 42 304 comprising the entire data set by identifying genes having the largest variance in their expression across all of the data points, by making use of the genefilter R package in Bioconductor (www.bioconductor.org), 20,21 resulting in a data set comprised of 424 genes. Genes having interactions specific to the sIBM disease cases were then identified by finding genes having unique indicator values present in all of the sIBM samples, that are not present in any of the polymyositis or control samples. An sIBM specific interaction network was then generated by calculating partial correlations between all genes for each k based on the regression estimates as described above. Then the interactions with the largest partial correlations for the respective indicator variables, within the subset of genes showing sIBM sample specific interactions, were selected so as to give a sparse estimate of the interaction network.
 ###### 
From cou.: 90 The accuracy of our methodology was first evaluated by generating synthetic data for 10 genes with a known underlying network structure, that varies over 30 data points. Some genes were assigned interactions that remained constant across all of the data points, whereas others were involved in interactions that were specific to certain groups of data points. We ran our method over 5000 Gibbs sampler iterations, collecting 500 samples after 4500 burn-in iterations, to infer the interactions of each gene and estimate how they varied.
From Soup: 90 The resulting network, illustrated in Fig. 5 , contains a number of genes that are known to be involved in sIBM, for example CXCR4 has previously been found to be involved in IBM, 22 as well as IGHM, 23 CIITA 24 and CCL13. 25 There are also several genes having a larger than average number of interactions that could be considered hubs within the network, for example HIST1H4J, SFRP4, SLFN12L and IGKV1D-27 and IGKV4-1, which stand out as strong candidates for further experimental exploration. However, hubs may not always be the most significant nodes in a network, as genes having few interactions may still play a crucial role, and so other candidates might be considered, for example those we predict to interact with genes having a known involvement in sIBM, such as the neighbouring genes of CXCR4.
 ###### 
From cou.: 91 The output of the method is plotted in Fig. 4, with genes whose interactions did not change between data points (6 out of 10, all of which were correctly identified by our method) omitted for clarity. Our results show that the method correctly identifies the genes whose interactions vary in specific sets of data points, and whilst the identification of the nature of the variations between data points is not perfect, we use a realistically small number of samples, so that perfect accuracy is not to be expected. It is also worth noting that whilst we infer some superfluous clusters in Fig. 4(a, c, d), these are almost entirely unique to the relevant groups of data points and do not incorrectly span multiple interaction sets. For example in Fig. 4(d), whilst data points 1–20 should share one set of interactions, two are incorrectly inferred, but these are correctly inferred to be unique to data points 1–20, and do not appear for data points 21–30.
From Soup: 91 To further validate our results we analysed the set of genes in the sIBM specific network using the ToppGene package, 26 that performs enrichment analysis of a set of genes in a number of categories, including associated phenotypes. Performing an analysis on the set of genes having sIBM specific interactions, the gene set was found to be significantly enriched for genes associated to the phenotypes of vasculitis, Rheumatoid arthritis and recurrent bacterial infections; when considering the full set of 424 genes used in our method no such enrichment was found. This suggests a relationship with genes involved in inflammation, and is an interesting result for future investigations.
 ###### 
From cou.: 92 We then applied our method to the sIBM data set described above, again running 5000 iterations of our Gibbs sampler with 4500 iterations of burn-in before collecting 500 samples. To render the analysis tractable we selected a subset of probes from the 42304 comprising the entire data set by identifying genes having the largest variance in their expression across all of the data points, by making use of the genefilter R package in Bioconductor (www.bioconductor.org),20,21 resulting in a data set comprised of 424 genes. Genes having interactions specific to the sIBM disease cases were then identified by finding genes having unique indicator values present in all of the sIBM samples, that are not present in any of the polymyositis or control samples. An sIBM specific interaction network was then generated by calculating partial correlations between all genes for each k based on the regression estimates as described above. Then the interactions with the largest partial correlations for the respective indicator variables, within the subset of genes showing sIBM sample specific interactions, were selected so as to give a sparse estimate of the interaction network.
From Soup: 92 As the performance of our method on the test data illustrates, we are able to identify genes whose interactions change in certain cases, or sets of data points, with the level of accuracy required to distill useful functional hypotheses from clinical observations. Such hypotheses in turn will allow researchers to explore further experimental avenues, and provide clinicians with potential leads as to which avenues should be further explored, or which tests ought be performed. The ability to not only identify changes in regulatory interactions, but also to allow us to take advantage of data spanning multiple cases is a valuable tool — our method can be seen not only as one that determines differences between data sets, but also as a means of integrating data from multiple sources. By allowing for (unknown) parts of the network to vary among the samples we increase statistical power and maintain the ability to discriminate between e.g. cases and controls at the regulatory level. Even considering only the genes in the network for which interactions do not vary, we enhance the inference of network structures by allowing data from multiple conditions or cases to be used.
 ###### 
From cou.: 93 The resulting network, illustrated in Fig. 5, contains a number of genes that are known to be involved in sIBM, for example CXCR4 has previously been found to be involved in IBM,22 as well as IGHM,23 CIITA24 and CCL13.25 There are also several genes having a larger than average number of interactions that could be considered hubs within the network, for example HIST1H4J, SFRP4, SLFN12L and IGKV1D-27 and IGKV4-1, which stand out as strong candidates for further experimental exploration. However, hubs may not always be the most significant nodes in a network, as genes having few interactions may still play a crucial role, and so other candidates might be considered, for example those we predict to interact with genes having a known involvement in sIBM, such as the neighbouring genes of CXCR4.
From Soup: 93 In our specific application the Bayesian nonparametric framework is valuable for a number of reasons. The Bayesian nonparametric approach we take allows us to avoid any restrictive assumptions about the true number of distinct regulatory network configurations a gene may possess both within and across data sets. In cases where we are considering expression profiles for hundreds or thousands of genes it is not realistic to presume to be able to provide such a priori knowledge. Thus our method is—to our knowledge—uniquely suited for such cases. It also avoids complex and difficult to tune reversible jump MCMC methods, whilst still delivering flexibility to describe the (unknown) complexity of the model. Finally, the method will scale naturally as increasingly large numbers of data points become available, without requiring adjustment of the methodology, as there is no predefined limit on the number of different network structures.
 ###### 
From cou.: 94 To further validate our results we analysed the set of genes in the sIBM specific network using the ToppGene package,26 that performs enrichment analysis of a set of genes in a number of categories, including associated phenotypes. Performing an analysis on the set of genes having sIBM specific interactions, the gene set was found to be significantly enriched for genes associated to the phenotypes of vasculitis, Rheumatoid arthritis and recurrent bacterial infections; when considering the full set of 424 genes used in our method no such enrichment was found. This suggests a relationship with genes involved in inflammation, and is an interesting result for future investigations.
From Soup: 94 As we have stated above, in modelling regulatory networks based on incomplete observations of the molecular processes at work in the cell (as is of course the case when considering gene expression data), it is crucial to include the potential for regulatory interactions to vary between conditions or over time in the model. Failing to do so assumes an inherently incorrect model and thus will generally not allow the model to correctly explain the observed data. The approach we propose adds complexity to the model only where required to explain the observed data, and in the process identifies genes whose behaviour may be of interest. For example it is possible to identify whose interactions appear to vary under a specific condition of interest, and to thus this approach has distinct benefits not only as regards the accuracy of the inference but also in the insights that may be gained from this analysis.
 ###### 
From cou.: 95 As the performance of our method on the test data illustrates, we are able to identify genes whose interactions change in certain cases, or sets of data points, with the level of accuracy required to distill useful functional hypotheses from clinical observations. Such hypotheses in turn will allow researchers to explore further experimental avenues, and provide clinicians with potential leads as to which avenues should be further explored, or which tests ought be performed. The ability to not only identify changes in regulatory interactions, but also to allow us to take advantage of data spanning multiple cases is a valuable tool — our method can be seen not only as one that determines differences between data sets, but also as a means of integrating data from multiple sources. By allowing for (unknown) parts of the network to vary among the samples we increase statistical power and maintain the ability to discriminate between e.g. cases and controls at the regulatory level. Even considering only the genes in the network for which interactions do not vary, we enhance the inference of network structures by allowing data from multiple conditions or cases to be used.
From Soup: 95 The inference scheme we chose to apply here is of course not the only possible choice, and much work has been done on inference schemes for the HDP. Another avenue which we hope to explore further is the use of variational inference for the HDP, as described in Teh et al. , 27 which would likely provide further improvements in computational efficiency, allowing even larger data sets to be considered.
 ###### 
From cou.: 96 In our specific application the Bayesian nonparametric framework is valuable for a number of reasons. The Bayesian nonparametric approach we take allows us to avoid any restrictive assumptions about the true number of distinct regulatory network configurations a gene may possess both within and across data sets. In cases where we are considering expression profiles for hundreds or thousands of genes it is not realistic to presume to be able to provide such a priori knowledge. Thus our method is—to our knowledge—uniquely suited for such cases. It also avoids complex and difficult to tune reversible jump MCMC methods, whilst still delivering flexibility to describe the (unknown) complexity of the model. Finally, the method will scale naturally as increasingly large numbers of data points become available, without requiring adjustment of the methodology, as there is no predefined limit on the number of different network structures.
From Soup: 96 We present a method for inference of regulatory network structures that is ideally suited for the types of problems that are increasingly being considered in systems medicine. The statistical model employed in the analysis is both flexible and parsimonious and naturally adapts to the amount and quality of the data available. The approach provides a robust framework for the inference of regulatory networks and their respective changes between conditions. From such information functional and mechanistic hypotheses are readily distilled for further analysis. In the context of systems medicine our approach has allowed us to detect new interactions among the genes involved in sIBM. Here we have also shown how the nuanced analysis afforded by simultaneously analyzing patients and controls in a single coherent inferential framework generates new mechanistic insights and provides novel testable hypotheses.
 ###### 
From cou.: 97 As we have stated above, in modelling regulatory networks based on incomplete observations of the molecular processes at work in the cell (as is of course the case when considering gene expression data), it is crucial to include the potential for regulatory interactions to vary between conditions or over time in the model. Failing to do so assumes an inherently incorrect model and thus will generally not allow the model to correctly explain the observed data. The approach we propose adds complexity to the model only where required to explain the observed data, and in the process identifies genes whose behaviour may be of interest. For example it is possible to identify whose interactions appear to vary under a specific condition of interest, and to thus this approach has distinct benefits not only as regards the accuracy of the inference but also in the insights that may be gained from this analysis.
From Soup: 97 V. V. Askanas and W. K. W. Engel, Curr. Opin. Rheumatol. , 2007, 19 , 550–559 Search PubMed .
 ###### 
From cou.: 98 The inference scheme we chose to apply here is of course not the only possible choice, and much work has been done on inference schemes for the HDP. Another avenue which we hope to explore further is the use of variational inference for the HDP, as described in Teh et al.,27 which would likely provide further improvements in computational efficiency, allowing even larger data sets to be considered.
From Soup: 98 M. C. Dalakas, Nat. Clin. Pract. Neurol. , 2006, 2 , 437–447 Search PubMed .
 ###### 
From cou.: 99 We present a method for inference of regulatory network structures that is ideally suited for the types of problems that are increasingly being considered in systems medicine. The statistical model employed in the analysis is both flexible and parsimonious and naturally adapts to the amount and quality of the data available. The approach provides a robust framework for the inference of regulatory networks and their respective changes between conditions. From such information functional and mechanistic hypotheses are readily distilled for further analysis. In the context of systems medicine our approach has allowed us to detect new interactions among the genes involved in sIBM. Here we have also shown how the nuanced analysis afforded by simultaneously analyzing patients and controls in a single coherent inferential framework generates new mechanistic insights and provides novel testable hypotheses.
From Soup: 99 S. Lèbre, J. Becq, F. Devaux, M. P. H. Stumpf and G. Lelandais, BMC Syst. Biol. , 2010, 4 , 130 Search PubMed .
 ###### 
From cou.: 100 V. V. Askanas and W. K. W. Engel, Curr. Opin. Rheumatol., 2007, 19, 550–559 Search PubMed .
From Soup: 100 M. Grzegorczyk, D. Husmeier, K. D. Edwards, P. Ghazal and A. J. Millar, Bioinformatics , 2008, 24 , 2071–2078 Search PubMed .
 ###### 
From cou.: 101 M. C. Dalakas, Nat. Clin. Pract. Neurol., 2006, 2, 437–447 Search PubMed .
From Soup: 101 T. Thorne and M. P. H. Stumpf, Bioinformatics , 2012, 28 , 3298–3305 Search PubMed .
 ###### 
From cou.: 102 S. Lèbre, J. Becq, F. Devaux, M. P. H. Stumpf and G. Lelandais, BMC Syst. Biol., 2010, 4, 130 Search PubMed .
From Soup: 102 C. A. C. Penfold, V. V. Buchanan-Wollaston, K. J. K. Denby and D. L. D. Wild, Bioinformatics , 2012, 28 , i233–i241 Search PubMed .
 ###### 
From cou.: 103 M. Grzegorczyk, D. Husmeier, K. D. Edwards, P. Ghazal and A. J. Millar, Bioinformatics, 2008, 24, 2071–2078 Search PubMed .
From Soup: 103 J. Chiquet, Y. Grandvalet and C. Ambroise, Statistics and Computing , 2011, 21 , 537–553 Search PubMed .
 ###### 
From cou.: 104 T. Thorne and M. P. H. Stumpf, Bioinformatics, 2012, 28, 3298–3305 Search PubMed .
From Soup: 104 J. Schäfer and K. Strimmer, Bioinformatics , 2005, 21 , 754–764 .
 ###### 
From cou.: 105 C. A. C. Penfold, V. V. Buchanan-Wollaston, K. J. K. Denby and D. L. D. Wild, Bioinformatics, 2012, 28, i233–i241 Search PubMed .
From Soup: 105 R. Opgen-Rhein and K. Strimmer, BMC Syst. Biol. , 2007, 1 , 37 Search PubMed .
 ###### 
From cou.: 106 J. Chiquet, Y. Grandvalet and C. Ambroise, Statistics and Computing, 2011, 21, 537–553 Search PubMed .
From Soup: 106 S. Lèbre, Stat. Appl. Genet. Mol. Biol. , 2009, 8 , Article 9 Search PubMed .
 ###### 
From cou.: 107 J. Schäfer and K. Strimmer, Bioinformatics, 2005, 21, 754–764 .
From Soup: 107 S. Lauritzen, Graphical models , Oxford University Press, 1996 Search PubMed .
 ###### 
From cou.: 108 R. Opgen-Rhein and K. Strimmer, BMC Syst. Biol., 2007, 1, 37 Search PubMed .
From Soup: 108 N. Krämer, J. Schäfer and A.-L. Boulesteix, BMC Bioinf. , 2009, 10 , 384 Search PubMed .
 ###### 
From cou.: 109 S. Lèbre, Stat. Appl. Genet. Mol. Biol., 2009, 8, Article 9 Search PubMed .
From Soup: 109 F. Caron and A. Doucet, ICML '08: Proceedings of the 25th international conference on Machine learning , 2008 Search PubMed .
 ###### 
From cou.: 110 S. Lauritzen, Graphical models, Oxford University Press, 1996 Search PubMed .
From Soup: 110 B. Clarke, E. Fokoue and H. H. Zhang, Principles and Theory for Data Mining and Machine Learning , Springer, 2009 Search PubMed .
 ###### 
From cou.: 111 N. Krämer, J. Schäfer and A.-L. Boulesteix, BMC Bioinf., 2009, 10, 384 Search PubMed .
From Soup: 111 T. S. Ferguson, Ann. Stat. , 1973, 1 , 209–230 Search PubMed .
 ###### 
From cou.: 112 F. Caron and A. Doucet, ICML '08: Proceedings of the 25th international conference on Machine learning, 2008 Search PubMed .
From Soup: 112 Y. Teh, M. Jordan, M. Beal and D. Blei, J. Am. Stat. Assoc. , 2006, 101 , 1566–1581 Search PubMed .
 ###### 
From cou.: 113 B. Clarke, E. Fokoue and H. H. Zhang, Principles and Theory for Data Mining and Machine Learning, Springer, 2009 Search PubMed .
From Soup: 113 B. S. B. Carvalho and R. A. R. Irizarry, Bioinformatics , 2010, 26 , 2363–2367 Search PubMed .
 ###### 
From cou.: 114 T. S. Ferguson, Ann. Stat., 1973, 1, 209–230 Search PubMed .
From Soup: 114 G. Smyth, Bioinformatics and and computational biology solutions using R and and Bioconductor , Springer, 2005 Search PubMed .
 ###### 
From cou.: 115 Y. Teh, M. Jordan, M. Beal and D. Blei, J. Am. Stat. Assoc., 2006, 101, 1566–1581 Search PubMed .
From Soup: 115 R. A. Irizarry, B. Hobbs, F. Collin, Y. D. Beazer-Barclay, K. J. Antonellis, U. Scherf and T. P. Speed, Biostatistics , 2003, 4 , 249–264 CrossRef .
 ###### 
From cou.: 116 B. S. B. Carvalho and R. A. R. Irizarry, Bioinformatics, 2010, 26, 2363–2367 Search PubMed .
From Soup: 116 R Development Core Team, R: A Language and Environment for Statistical Computing , R Foundation for Statistical Computing, Vienna, Austria, 2011 Search PubMed .
 ###### 
From cou.: 117 G. Smyth, Bioinformatics and and computational biology solutions using R and and Bioconductor, Springer, 2005 Search PubMed .
From Soup: 117 R. Gentleman, V. Carey, W. Huber and F. Hahne, genefilter: methods for filtering genes from microarray experiments , 2007 Search PubMed .
 ###### 
From cou.: 118 R. A. Irizarry, B. Hobbs, F. Collin, Y. D. Beazer-Barclay, K. J. Antonellis, U. Scherf and T. P. Speed, Biostatistics, 2003, 4, 249–264 CrossRef .
From Soup: 118 B. De Paepe, K. K. Creus and J. L. De Bleecker, Ann. N. Y. Acad. Sci. , 2007, 1109 , 441–453 Search PubMed .
 ###### 
From cou.: 119 R Development Core Team, R: A Language and Environment for Statistical Computing, R Foundation for Statistical Computing, Vienna, Austria, 2011 Search PubMed .
From Soup: 119 K. C. K. Parker, S. W. S. Kong, R. J. R. Walsh, M. M. Salajegheh, B. B. Moghadaszadeh, A. A. A. Amato, R. R. Nazareno, Y. Y. Y. Lin, B. B. Krastins, D. A. D. Sarracino, A. H. A. Beggs, J. L. J. Pinkus and S. A. S. Greenberg, Muscle Nerve , 2009, 39 , 739–753 Search PubMed .
 ###### 
From cou.: 120 R. Gentleman, V. Carey, W. Huber and F. Hahne, genefilter: methods for filtering genes from microarray experiments, 2007 Search PubMed .
From Soup: 120 J. Ivanidze, R. Hoffmann, H. Lochmüller, A. G. Engel, R. Hohlfeld and K. Dornmair, Am. J. Pathol. , 2011, 179 , 13 Search PubMed .
 ###### 
From cou.: 121 B. De Paepe, K. K. Creus and J. L. De Bleecker, Ann. N. Y. Acad. Sci., 2007, 1109, 441–453 Search PubMed .
From Soup: 121 R. R. Raju and M. C. M. Dalakas, Brain , 2005, 128 , 1887–1896 Search PubMed .
 ###### 
From cou.: 122 K. C. K. Parker, S. W. S. Kong, R. J. R. Walsh, M. M. Salajegheh, B. B. Moghadaszadeh, A. A. A. Amato, R. R. Nazareno, Y. Y. Y. Lin, B. B. Krastins, D. A. D. Sarracino, A. H. A. Beggs, J. L. J. Pinkus and S. A. S. Greenberg, Muscle Nerve, 2009, 39, 739–753 Search PubMed .
From Soup: 122 J. J. Chen, E. E. E. Bardes, B. J. B. Aronow and A. G. A. Jegga, Nucleic Acids Res. , 2009, 37 , W305–W311 Search PubMed .
 ###### 
From cou.: 123 J. Ivanidze, R. Hoffmann, H. Lochmüller, A. G. Engel, R. Hohlfeld and K. Dornmair, Am. J. Pathol., 2011, 179, 13 Search PubMed .
From Soup: 123 Y. W. Teh, K. Kurihara and M. Welling, Advances in Neural Information Processing Systems , 2008, vol. 20, pp. 1481–1488 Search PubMed .
 ###### 
From cou.: 124 R. R. Raju and M. C. M. Dalakas, Brain, 2005, 128, 1887–1896 Search PubMed .
From cou.: 125 J. J. Chen, E. E. E. Bardes, B. J. B. Aronow and A. G. A. Jegga, Nucleic Acids Res., 2009, 37, W305–W311 Search PubMed .
From cou.: 126 Y. W. Teh, K. Kurihara and M. Welling, Advances in Neural Information Processing Systems, 2008, vol. 20, pp. 1481–1488 Search PubMed .
